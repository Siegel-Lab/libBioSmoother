{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test normalizaitons\n",
    "## basic settings first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"11235\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"11235\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\": \"XypntL49z55iwGVUW4qsEu83zKL3XEcz0MjuGOQ9SlaaQ68X/g+k1FcioZi7oQAc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\": \"bEsM86IHGDTLCS0Zod8a8WM6Y4+lafAL/eSiyQcuPzinmWNgNO2/olUF0Z2Dkn5i\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\": \"TX0gSQTdXTTeScqxj6PVQxTiRW8DOoGVwinyi1D3kxv7wuxQ02XkOxv0xwiypcAH\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"11235\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import libsmoother\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import viridis\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.layouts import column\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "KBP = 1000\n",
    "MBP = 1000 * KBP\n",
    "\n",
    "WINDOW_SIZES = [500 * KBP, 1 * MBP, 5 * MBP] # [1 * MBP]\n",
    "BIN_SIZES = [50 * KBP, 100 * KBP] # [100*KBP]\n",
    "NUM_SAMPLES = [4**x for x in range(8)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define basic evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "def lib_sps_print(s):\n",
    "    pass\n",
    "\n",
    "def conf_quarry_basic(quarry):\n",
    "    #warnings.filterwarnings('ignore')\n",
    "    with libsmoother.open_default_json() as default_file:\n",
    "        default_json = json.load(default_file)\n",
    "        quarry.set_value([\"settings\"], default_json)\n",
    "    quarry.set_value([\"settings\", \"filters\", \"symmetry\"], \"mirror\")\n",
    "    quarry.set_value([\"settings\", \"filters\", \"cut_off_bin\"], \"smaller\")\n",
    "    quarry.set_value([\"settings\", \"filters\", \"show_contig_smaller_than_bin\"], True)\n",
    "    quarry.set_value([\"settings\", \"interface\", \"fixed_bin_size\"], True)\n",
    "    quarry.set_value([\"settings\", \"interface\", \"add_draw_area\", \"val\"], 0)\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"scale\"], \"dont\")\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"log_base\", \"val\"], 0)\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"ice_sparse_slice_filter\", \"val\"], 0)\n",
    "\n",
    "\n",
    "def conf_quarry_data(quarry):\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"scale\"], \"dont\")\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"log_base\", \"val\"], 0)\n",
    "\n",
    "def conf_quarry_heatmap(quarry):\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"scale\"], \"max\")\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"log_base\", \"val\"], 10)\n",
    "\n",
    "\n",
    "def set_bin_size(quarry, bin_size):\n",
    "    div = quarry.get_value([\"dividend\"])\n",
    "    if bin_size % div != 0:\n",
    "        print(\"WARNING: uneven division by index dividend\", file=sys.stderr)\n",
    "    if bin_size < div:\n",
    "        print(\"WARNING: dividend larger than value\", file=sys.stderr)\n",
    "    bin_size = max(1, bin_size // div)\n",
    "    quarry.set_value([\"settings\", \"interface\", \"fixed_bin_size_x\", \"val\"], bin_size)\n",
    "    quarry.set_value([\"settings\", \"interface\", \"fixed_bin_size_y\", \"val\"], bin_size)\n",
    "\n",
    "def tsv_to_ret(data, key, tsv):\n",
    "    ret = [(x[:-1], x[-1]) for x in tsv]\n",
    "    ret.sort()\n",
    "    data[key + (\"bin_coords\", )] = [a for a, _ in ret]\n",
    "    data[key + (\"bin_vals\", )] = [b for _, b in ret]\n",
    "\n",
    "def quarry_whole_window(data, key, quarry):\n",
    "    canvas_size_x, canvas_size_y = quarry.get_canvas_size(lib_sps_print)\n",
    "    quarry.set_value([\"area\", \"x_start\"], 0)\n",
    "    quarry.set_value([\"area\", \"x_end\"], canvas_size_x)\n",
    "    quarry.set_value([\"area\", \"y_start\"], 0)\n",
    "    quarry.set_value([\"area\", \"y_end\"], canvas_size_y)\n",
    "    \n",
    "    conf_quarry_data(quarry)\n",
    "    tsv_to_ret(data, key, quarry.get_heatmap_export(lib_sps_print))\n",
    "    \n",
    "    conf_quarry_heatmap(quarry)\n",
    "    data[key + (\"heatmap\", )] = quarry.get_heatmap(lib_sps_print)\n",
    "\n",
    "def quarry_chunked_window(data, data_key, quarry, window_size):\n",
    "    canvas_size_x, canvas_size_y = quarry.get_canvas_size(lambda s: None)\n",
    "    tsv = []\n",
    "    heatmap = None\n",
    "    for x_start in range(0, canvas_size_x, window_size):\n",
    "        quarry.set_value([\"area\", \"x_start\"], x_start)\n",
    "        quarry.set_value([\"area\", \"x_end\"], x_start + window_size)\n",
    "        for y_start in range(0, canvas_size_y, window_size):\n",
    "            quarry.set_value([\"area\", \"y_start\"], y_start)\n",
    "            quarry.set_value([\"area\", \"y_end\"], y_start + window_size)\n",
    "            conf_quarry_data(quarry)\n",
    "            tsv.extend(quarry.get_heatmap_export(lib_sps_print))\n",
    "            \n",
    "            conf_quarry_heatmap(quarry)\n",
    "            heatmap_local = quarry.get_heatmap(lib_sps_print)\n",
    "            if heatmap is None:\n",
    "                heatmap = heatmap_local\n",
    "            else:\n",
    "                for key, val in heatmap_local.items():\n",
    "                    heatmap[key].extend(val)\n",
    "    tsv_to_ret(data, data_key, tsv)\n",
    "    data[data_key + (\"heatmap\", )] = heatmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load index and compute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_size 50000\n",
      "cooler\n"
     ]
    }
   ],
   "source": [
    "quarry = libsmoother.Quarry(\"../../smoother_out/radicl.smoother_index\")\n",
    "conf_quarry_basic(quarry)\n",
    "\n",
    "data = {}\n",
    "\n",
    "for bin_size in BIN_SIZES:\n",
    "    print(\"bin_size\", bin_size)\n",
    "\n",
    "    set_bin_size(quarry, bin_size)\n",
    "    print(\"cooler\")\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"normalize_by\"], \"cool-ice\")\n",
    "    quarry_whole_window(data, (\"ICE\", \"cooler\", bin_size), quarry)\n",
    "\n",
    "    print(\"raw data\")\n",
    "    quarry.set_value([\"settings\", \"normalization\", \"normalize_by\"], \"dont\")\n",
    "    quarry_whole_window(data, (\"ICE\", \"neg-ctrl\", bin_size), quarry)\n",
    "\n",
    "    for window_size in WINDOW_SIZES:\n",
    "        print(\"window_size\", window_size)\n",
    "\n",
    "        if False:\n",
    "            print(\"local-ice\")\n",
    "            quarry.set_value([\"settings\", \"normalization\", \"normalize_by\"], \"ice\")\n",
    "            quarry.set_value([\"settings\", \"normalization\", \"ice_local\"], True)\n",
    "            quarry_whole_window(data, (\"ICE\", \"local\", bin_size, window_size), quarry)\n",
    "            assert data[(\"ICE\", \"cooler\", bin_size, window_size, \"bin_coords\")] == \\\n",
    "                   data[(\"ICE\", \"local\", bin_size, window_size, \"bin_coords\")]\n",
    "            \n",
    "            print(\"symm-ice\")\n",
    "            quarry.set_value([\"settings\", \"normalization\", \"normalize_by\"], \"symm-ice\")\n",
    "            quarry.set_value([\"settings\", \"normalization\", \"ice_local\"], True)\n",
    "            quarry_whole_window(data, (\"ICE\", \"symm\", bin_size, window_size), quarry)\n",
    "            assert data[(\"ICE\", \"cooler\", bin_size, window_size, \"bin_coords\")] == \\\n",
    "                   data[(\"ICE\", \"symm\", bin_size, window_size, \"bin_coords\")]\n",
    "\n",
    "        quarry.set_value([\"settings\", \"normalization\", \"normalize_by\"], \"ice\")\n",
    "        quarry.set_value([\"settings\", \"normalization\", \"ice_local\"], False)\n",
    "        for num_samples in NUM_SAMPLES:\n",
    "            print(\"global-ice\", num_samples)\n",
    "            quarry.set_value([\"settings\", \"normalization\", \"num_ice_bins\", \"val\"], num_samples)\n",
    "            \n",
    "            quarry_chunked_window(data, (\"ICE\", \"global\", bin_size, window_size, num_samples), \n",
    "                                  quarry, window_size)\n",
    "        assert data[(\"ICE\", \"cooler\", bin_size, window_size, \"bin_coords\")] == \\\n",
    "               data[(\"ICE\", \"global\", bin_size, window_size, num_samples, \"bin_coords\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the point scatter plot for one bin and window size\n",
    "\n",
    "Expect a bad correleation for a low number of samples, it should then gradually improve with the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from bokeh.models import Legend\n",
    "\n",
    "def get_mean_dev(ground_truth, points):\n",
    "    return sum(abs(a-b) for a, b in zip(ground_truth, points)) / len(points)\n",
    "\n",
    "\n",
    "def plot_scatter_points(ground_truth, data, title):\n",
    "    ALMOST_ZERO = 10**-5\n",
    "    palette = viridis(sum(1 if c is None else 0 for _1, _2, c in data))\n",
    "    f = figure(\n",
    "            title=title, \n",
    "            x_axis_type=\"log\", \n",
    "            y_axis_type=\"log\", \n",
    "            x_range=(ALMOST_ZERO, 10**5), \n",
    "            y_range=(ALMOST_ZERO, 10**5),\n",
    "            sizing_mode=\"stretch_width\",\n",
    "        )\n",
    "    f.line(x=[ALMOST_ZERO,1], y=[ALMOST_ZERO,1], color=\"black\")\n",
    "    items = []\n",
    "    idx = 0\n",
    "    for name, points, color in data:\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for (x, y) in random.sample(list(zip(ground_truth, points)), min(len(points), 1000)):\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        mean_dev = round(get_mean_dev(ground_truth, points), 5)\n",
    "        d = f.dot(x=xs, y=ys, color=palette[idx] if color is None else color, size=25, alpha=0.5)\n",
    "        idx += 1 if color is None else 0\n",
    "        items.append((name + \" dev: \" + str(mean_dev), [d]))\n",
    "\n",
    "    f.xaxis.axis_label = \"ground truth\"\n",
    "    f.yaxis.axis_label = \"sample\"\n",
    "    f.add_layout(Legend(items=items, location=\"center\", click_policy=\"hide\"), \"right\")\n",
    "    show(f)\n",
    "\n",
    "plot_scatter_points(\n",
    "    data[(\"ICE\", \"cooler\", BIN_SIZES[0], \"bin_vals\")], \n",
    "    [(\"unnormalized\", data[(\"ICE\", \"neg-ctrl\", BIN_SIZES[0], \"bin_vals\")], \"red\")] +\n",
    "    [(\"num samples = \" + str(num_samples), \n",
    "      data[(\"ICE\", \"global\", BIN_SIZES[0], WINDOW_SIZES[0], num_samples, \"bin_vals\")], None) for num_samples in NUM_SAMPLES[:-2]], \n",
    "    \"chunked global ice vs cooler, bin-size= \" + str(BIN_SIZES[0] // KBP) + \"k window-size= \" + str(WINDOW_SIZES[0]//KBP) + \"k\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean deviation becomes smaller with increasing number of samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_scatter_points(data[(\"ICE\", \"cooler\", BIN_SIZES[0], \"bin_vals\")], \n",
    "                        [(\"local ice bins\", data[(\"ICE\", \"local\", BIN_SIZES[0], WINDOW_SIZES[0], \"bin_vals\")])], \"local ice vs cooler\")\n",
    "    plot_scatter_points(data[(\"ICE\", \"cooler\", BIN_SIZES[0], \"bin_vals\")], \n",
    "                        [(\"local ice bins\", data[(\"ICE\", \"symm\", BIN_SIZES[0], WINDOW_SIZES[0], \"bin_vals\")])], \"symm ice vs cooler\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- equally, this has a mean deviation of 0.001, so it's not the number of samples but some glitch in the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot mean deviation as a function of the number of samples for all bin and window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_as_func_of_samples(conditions):\n",
    "    palette = viridis(len(conditions))\n",
    "    f = figure(\n",
    "            y_axis_type=\"log\", x_axis_type=\"log\"\n",
    "        )\n",
    "    idx = 0\n",
    "    for ground_truth, sample, name in conditions:\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for num_samples, points in sample:\n",
    "            xs.append(num_samples)\n",
    "            ys.append(get_mean_dev(ground_truth, points))\n",
    "        f.line(x=xs, y=ys, color=palette[idx], legend_label=name)\n",
    "        f.x(x=xs, y=ys, color=palette[idx], legend_label=name)\n",
    "        idx += 1\n",
    "    f.xaxis.axis_label = \"number of samples\"\n",
    "    f.yaxis.axis_label = \"mean deviation\"\n",
    "    f.legend.click_policy=\"hide\"\n",
    "    show(f)\n",
    "\n",
    "conditions = [\n",
    "    (\n",
    "        data[(\"ICE\", \"cooler\", bin_size, window_size, \"bin_vals\")], \n",
    "        [(num_samples, data[(\"ICE\", \"global\", bin_size, window_size, num_samples, \"bin_vals\")]) for num_samples in NUM_SAMPLES], \n",
    "        \"ICE bin_size=\" + str(bin_size//KBP) + \"k window_size=\" + str(window_size//KBP) + \"k\"\n",
    "     ) \n",
    "     for bin_size in BIN_SIZES for window_size in WINDOW_SIZES\n",
    "]\n",
    "\n",
    "corr_as_func_of_samples(conditions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- windows size does not affect results\n",
    "- bin size does"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some of the heatmaps for a visual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_RANGE=(0, 501)\n",
    "def plot_heatmap(datas, bg_color, x_range=DEFAULT_RANGE, y_range=DEFAULT_RANGE):\n",
    "    fl = []\n",
    "    for data, title in datas:\n",
    "        if len(fl) == 0:\n",
    "            f = figure(title=title)\n",
    "        else:\n",
    "            f = figure(title=title, x_range=fl[0].x_range, y_range=fl[0].y_range)\n",
    "        d_filtered = {}\n",
    "        for key, vals in data.items():\n",
    "            d_filtered[key] = []\n",
    "            for idx, v in enumerate(vals):\n",
    "                if data[\"screen_left\"][idx] >= x_range[0] and data[\"screen_right\"][idx] < x_range[1] and \\\n",
    "                data[\"screen_bottom\"][idx] >= y_range[0] and data[\"screen_top\"][idx] < y_range[1]:\n",
    "                    d_filtered[key].append(v)\n",
    "        f.quad(\n",
    "            left=\"screen_left\",\n",
    "            bottom=\"screen_bottom\",\n",
    "            right=\"screen_right\",\n",
    "            top=\"screen_top\",\n",
    "            fill_color=\"color\",\n",
    "            line_color=None,\n",
    "            source=ColumnDataSource(data=d_filtered),\n",
    "        )\n",
    "        f.background_fill_color = bg_color\n",
    "        f.grid.grid_line_color = None\n",
    "        f.axis.ticker = []\n",
    "\n",
    "        f.add_tools(\n",
    "            HoverTool(\n",
    "                tooltips=[\n",
    "                    (\n",
    "                        \"(x, y)\",\n",
    "                        \"(@chr_x @index_left .. @index_right, @chr_y @index_bottom .. @index_top)\",\n",
    "                    ),\n",
    "                    (\"score\", \"@score_total\"),\n",
    "                    (\"color\", \"@color\"),\n",
    "                    (\"reads by group\", \"A: @score_a, B: @score_b\"),\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        fl.append(f)\n",
    "    show(column(fl), notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap([\n",
    "    (data[(\"ICE\", \"cooler\", BIN_SIZES[-1], \"heatmap\")], \"cooler\"), \n",
    "    (data[(\"ICE\", \"global\", BIN_SIZES[-1], WINDOW_SIZES[0], NUM_SAMPLES[-1], \"heatmap\")], \"global-ice - num samples = \" + str(NUM_SAMPLES[-1])),\n",
    "    (data[(\"ICE\", \"global\", BIN_SIZES[-1], WINDOW_SIZES[0], NUM_SAMPLES[0], \"heatmap\")], \"global-ice - num samples = \" + str(NUM_SAMPLES[0])),\n",
    "    (data[(\"ICE\", \"neg-ctrl\", BIN_SIZES[-1], \"heatmap\")], \"raw data\"),\n",
    "    ], quarry.get_background_color(lib_sps_print))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sm_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
